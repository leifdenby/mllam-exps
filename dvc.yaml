stages:
  mllam_version:
    cmd: source machines/environment.sh; python -c "from neural_lam import __version__; print(__version__)" > version.mllam.txt
  prepare_dataset:
    cmd: python -m mllam_data_prep data/datastore.yaml --output data/datastore.zarr
    deps:
    - data/datastore.yaml
    outs:
    - data/datastore.zarr
  create_graph-slurm:
    cmd: python -m neural_lam.create_graph --config_path data/config.yaml --name 1level
      --levels 1
    params:
    - data/config.yaml:
      - datastore
    deps:
    - data/datastore.zarr
    outs:
    - data/graph/
  train:
    cmd:
    - sbatch -W machines/slurm.train.sh --config_path ./data/config.yaml --logger mlflow --logger_project ${experiment_name}
    params:
    - params.yaml:
      - experiment_name
      - num_nodes
      - model
      - graph
      - hidden_dim
      - processor_layers
      - metrics_watch
      - val_steps_to_log
    - data/training_params.yaml:
      - epochs
      - batch_size
      - num_nodes
    deps:
    - version.mllam.txt
    - data/graph/
    - data/config.yaml
    - data/datastore.yaml
    outs:
    - saved_models
  evaluate:
    cmd:
    - sbatch -W --nodes 1 machines/slurm.train.sh --config_path ./data/config.yaml --eval val --load
      ./saved_models/*/last.ckpt --logger mlflow --logger_project ${experiment_name}
    params:
    - params.yaml:
      - experiment_name
      - num_nodes
      - model
      - graph
      - hidden_dim
      - processor_layers
      - metrics_watch
      - val_steps_to_log
    - data/evaluate_params.yaml:
      - epochs
      - batch_size
      - num_workers
    deps:
    - version.mllam.txt
    - data/graph/
    - data/config.yaml
    - data/datastore.yaml
    - saved_models
    outs:
    - mlruns
